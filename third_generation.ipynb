{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk                   #Only show the difference\n",
    "from operator import eq \n",
    "\n",
    "def OpinosisGraph(Z, G, PRI):\n",
    "    for i in range(len(Z)):  \n",
    "        for j in range(len(Z[i])):  \n",
    "            LABEL = Z[i][j]\n",
    "            PID = j\n",
    "            SID = i\n",
    "            if LABEL in G:\n",
    "                PRI[LABEL].append((SID, PID))\n",
    "            else:\n",
    "                G[LABEL] = list()\n",
    "                PRI[LABEL] = [(SID, PID)]\n",
    "            if j > 0 and LABEL not in G[Z[i][j-1]]:\n",
    "                G[Z[i][j-1]].append(Z[i][j])\n",
    "                \n",
    "def VSN(node):\n",
    "    global PRI1\n",
    "    if node[1] in ['.']:\n",
    "        return False\n",
    "    sigma_vsn = 15\n",
    "    ele = PRI1[node]\n",
    "    sum = 0               \n",
    "    for i in range(len(ele)):\n",
    "        sum = sum + ele[i][1]\n",
    "    if sum/len(ele) > sigma_vsn:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def VEN(node):\n",
    "    prohibit = ['and', 'but', 'for', 'nor', 'or', 'so', 'yet', ',', '.', '!', '?', ';',':',':']\n",
    "    if(node[0] in prohibit):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def collapsible(node):\n",
    "    if(node[1] == 'VERB'):\n",
    "        return True\n",
    "    else: \n",
    "        return False\n",
    "\n",
    "    \n",
    "def valid_sent(sent):                        \n",
    "    all = ['VERB','.','ADJ','PRON','NOUN','ADV','PRON','CONJ','PRT','ADP','NUM','DET','X']\n",
    "    count = dict()\n",
    "    for i in sent:\n",
    "        if i not in count:\n",
    "            count[i] = 1\n",
    "        else:\n",
    "            count[i] += 1\n",
    "    for i in count:\n",
    "        if i[1] in ['ADJ','ADV','NOUN'] and count[i] > 1:\n",
    "            return False\n",
    "    #the first kind of valid sentence\n",
    "    state = 0\n",
    "    for i in sent:\n",
    "        if state == 0 and i[1] == 'NOUN':\n",
    "            state = 1\n",
    "        if state == 1 and i[1] == 'VERB':\n",
    "            state = 2\n",
    "        if state == 2 and i[1] == 'ADJ':\n",
    "            state = 3\n",
    "    if state == 3:\n",
    "        return True\n",
    "    #the second kind of valid sentence\n",
    "    state = 0\n",
    "    for i in sent:\n",
    "        if state == 0 and i[1] == 'ADJ':\n",
    "            state = 2\n",
    "        if state == 1 and i[1] == 'DET':  \n",
    "            state = 2\n",
    "        if state == 2 and i[1] == 'VERB':\n",
    "            state = 3\n",
    "    if state == 3:\n",
    "        return True\n",
    "    #the third kind of valid sentence\n",
    "    state = 0\n",
    "    for i in sent:\n",
    "        if state == 0 and i[1] == 'ADV':\n",
    "            state = 1\n",
    "        if state == 1 and i[1] == 'ADJ':  \n",
    "            state = 2\n",
    "        if state == 2 and i[1] == 'NOUN':\n",
    "            state = 3\n",
    "    if state == 3:\n",
    "        return True\n",
    "    #the fourth kind of valid sentence\n",
    "    state = 0\n",
    "    for i in sent:\n",
    "        if state == 0 and i[1] == 'ADV':\n",
    "            state = 2\n",
    "        #if state == 1 and i[1] == 'VERB':  #?\n",
    "            #state = 2\n",
    "        if state == 2 and i[1] == 'NOUN':\n",
    "            state = 3\n",
    "    if state == 3:\n",
    "        return True\n",
    "    return False\n",
    "    \n",
    "\n",
    "def check_inter(PRIa,PRIb):\n",
    "    PRIc = []\n",
    "    sigma_gap = 4\n",
    "    for first in PRIa:\n",
    "        for second in PRIb:\n",
    "            if(first[0] == second[0] and abs(first[1]-second[1]) <= sigma_gap):\n",
    "                PRIc.append(second)\n",
    "                break\n",
    "    return PRIc\n",
    "\n",
    "def common_elements(list1, list2):\n",
    "    count = 0\n",
    "    for element in list1:\n",
    "        if element in list2:\n",
    "            count= count+1\n",
    "    return count\n",
    "                                            \n",
    "def jaccard_fail(a,b):\n",
    "    sigma_j = 0.8\n",
    "    inter = common_elements(a,b)\n",
    "    if ((inter/(len(a)+len(b)-inter)) >= sigma_j):\n",
    "        return True\n",
    "    if abs(inter-len(a)) < 3 or abs(inter-len(b)) < 3:\n",
    "        return True\n",
    "    return False\n",
    "    \n",
    "\n",
    "def eliminate_dup2(clist): \n",
    "    #print(clist)\n",
    "    buf = []\n",
    "    first = True\n",
    "    for ele in clist:\n",
    "        temp = []\n",
    "        similar = False\n",
    "        if(first):\n",
    "            buf.append(ele)\n",
    "            first = False\n",
    "        else:\n",
    "            for seen in buf:\n",
    "                if jaccard_fail(seen[0],ele[0]):\n",
    "                    similar = True\n",
    "                    if ele[1]>seen[1]:     \n",
    "                        temp.append(seen)\n",
    "            if len(temp) != 0:  \n",
    "                for seen in temp:\n",
    "                    buf.remove(seen)\n",
    "                buf.append(ele)\n",
    "            elif similar == False:\n",
    "                buf.append(ele) \n",
    "    return buf\n",
    "\n",
    "\n",
    "\n",
    "def find_avg_score(clist):\n",
    "    if len(clist)==0:\n",
    "        return 0\n",
    "    sum = 0\n",
    "    for ele in clist:\n",
    "        sum = sum + ele[1]\n",
    "    return sum/len(clist)\n",
    "\n",
    "def stitch_prev(Canchor,CC): \n",
    "    if len(CC) == 0:\n",
    "        return Canchor\n",
    "    CC = eliminate_dup2(CC) \n",
    "    winner = CC[0]\n",
    "    for ele in CC:\n",
    "        if ele[1] > winner[1]:\n",
    "            winner = ele\n",
    "    ans = []\n",
    "    return (Canchor+winner[0])\n",
    "\n",
    "def stitch(Canchor,CC): \n",
    "    if len(CC) == 0:\n",
    "        return Canchor\n",
    "    CC = eliminate_dup2(CC) \n",
    "    winner = CC[0]\n",
    "    buf = Canchor\n",
    "    for ele in CC:\n",
    "        buf = buf + ele[0]\n",
    "    return (Canchor+winner[0])\n",
    "\n",
    "def find_sum(C):\n",
    "    winner = (None,-1)\n",
    "    runner_up = (None,-1)\n",
    "    for i in range(len(C)):\n",
    "        if C[i][-1] in ['and', 'but', 'for', 'nor', 'or', 'so', 'yet']:\n",
    "            C[i] = C[i][:-1]\n",
    "    for ele in C:\n",
    "        if ele[1] > winner[1]:\n",
    "            if winner[1] > runner_up[1]:\n",
    "                runner_up = winner\n",
    "            winner = ele\n",
    "        elif ele[1] > runner_up[1]:\n",
    "            runner_up = ele\n",
    "    if(not winner[0] or not runner_up[0]):  \n",
    "        return (\"FAIL\",\"FAIL\")\n",
    "    ans1 = \"\"\n",
    "    for words in winner[0]:\n",
    "        ans1 = ans1 + words[0] + \" \"\n",
    "    ans1 = ans1[0].upper() + ans1[1:(len(ans1)-1)]\n",
    "    ans2 = \"\"\n",
    "    for words in runner_up[0]:\n",
    "        ans2 = ans2 + words[0] + \" \"\n",
    "    ans2 = ans2[0].upper() + ans2[1:(len(ans2)-1)]\n",
    "    return ans1,ans2\n",
    "\n",
    "def Traverse(clist,vk,score,PRI_overlap,sent,length):\n",
    "    global G1\n",
    "    global PRI1\n",
    "    global sigma_r        \n",
    "    redundancy = len(PRI_overlap)\n",
    "    if length>10:\n",
    "        return\n",
    "    if vk in sent[:-1] and vk[1] in ['ADJ','ADV']:\n",
    "        return\n",
    "    if (redundancy  >= sigma_r): \n",
    "        if (VEN(vk)):\n",
    "            if (valid_sent(sent)):\n",
    "                finalscore = score/length\n",
    "                clist.append((sent,finalscore))\n",
    "                return \n",
    "        for vn in G1[vk]:\n",
    "            PRI_new = PRI_overlap+check_inter(PRI_overlap,PRI1[vn]) #we use the second generation, but the old PRI is kept\n",
    "            redundancy = len(PRI_new)                               #different from the paper\n",
    "            new_sent = sent+[vn]\n",
    "            L = length + 1\n",
    "            new_score = score + redundancy \n",
    "            if (collapsible(vn)):\n",
    "                Canchor = new_sent\n",
    "                tmp = []\n",
    "                for vx in G1[vn]:\n",
    "                    if vx[1] not in ['.']:\n",
    "                        Traverse(tmp,vx,0,PRI_new,[vx],L)\n",
    "                    CC = eliminate_dup2(tmp) \n",
    "                    avg_CC_score = find_avg_score(CC)\n",
    "                    finalscore = new_score + avg_CC_score\n",
    "                    stitch_sent = stitch(Canchor,CC) \n",
    "                    if(valid_sent(stitch_sent)):\n",
    "                        clist.append((stitch_sent,finalscore))\n",
    "            else:\n",
    "                Traverse(clist,vn,new_score,PRI_new,new_sent,L)\n",
    "\n",
    "def first_lower(s):\n",
    "    if s[0] == \"I\":\n",
    "        return s[0] + s[1:].lower()\n",
    "    else:\n",
    "        return s.lower()\n",
    "        \n",
    "def read_text(file_name):\n",
    "    redundant = '<br />'\n",
    "    review = []\n",
    "    with open(file_name,'r') as file:\n",
    "        for article in file:\n",
    "            article = article.replace(redundant,\" \")\n",
    "            sentences = nltk.sent_tokenize(article)    \n",
    "            for sentence in sentences:\n",
    "                sentence = first_lower(sentence)\n",
    "                review.append(nltk.pos_tag(nltk.word_tokenize(sentence),tagset='universal'))\n",
    "                \n",
    "    file.close()\n",
    "    return review\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00_9.txt\n",
      "summary1:  The pettiness of the whole situation , the school , i\n",
      "summary2:  The whole situation , the pettiness of the school , i\n",
      "01_7.txt\n",
      "summary1:  The idiotic principal , mr. bip , the small stories going\n",
      "summary2:  The idiotic principal , mr. bip , tracy-ann oberman , smack\n",
      "02_9.txt\n",
      "summary1:  A students and teachers at a south london public school leaves\n",
      "summary2:  Of keisha , of a better term , the show does\n",
      "03_10.txt\n",
      "summary1:  At the orchestra pit -- or even at the theatre stopped\n",
      "summary2:  Is you and it needs more than your attention , it needs\n",
      "04_10.txt\n",
      "summary1:  The target of evil guys and `` the goon '' challenge\n",
      "summary2:  Of the target of the very best three stooges shorts\n",
      "05_10.txt\n",
      "summary1:  In in in the middle of this film so i had\n",
      "summary2:  In in in in in in south carolina , and danny\n",
      "06_7.txt\n",
      "summary1:  Movie , judging by the unusually low score imdb members have\n",
      "summary2:  The writing and the use of this movie is the spanish gives\n",
      "07_7.txt\n",
      "summary1:  A great in this film and there is delicate and there is\n",
      "summary2:  A film as a great cinematic entertainment , but i will\n",
      "08_7.txt\n",
      "summary1:  This way for someone who takes the sole supporter , drops\n",
      "summary2:  To fill in the viewers to have a few blank areas leaving\n",
      "09_9.txt\n",
      "summary1:  Is this , when a short is this good , who 's\n",
      "summary2:  A bit of true whodunit mystery in this , to meet\n",
      "10_9.txt\n",
      "summary1:  Of a story of a fine job , while deniro is\n",
      "summary2:  A fine job , while deniro is really a well done\n",
      "11_9.txt\n",
      "summary1:  Very convincing and felt\n",
      "summary2:  Very enjoyable movie .\n",
      "12_9 .txt\n",
      "summary1:  Enjoy the movie , just the right amount comedy to keep\n",
      "summary2:  Was so disappointed that it was a first time i still enjoy\n",
      "13_7.txt\n",
      "summary1:  Was a passable 2 star `` decent '' flick , ct\n",
      "summary2:  In a dead end factory job in a couple of working\n",
      "14_10.txt\n",
      "summary1:  With sudden emotion , and those which even put\n",
      "summary2:  With sudden emotion , and their best work , i caught\n",
      "15_8.txt\n",
      "summary1:  For this and the dreadful red queen figurine , i felt\n",
      "summary2:  The move and the whole thing constantly on the film is\n",
      "16_9.txt\n",
      "summary1:  Is this , when a short is this good , who 's\n",
      "summary2:  A bit of true whodunit mystery in this , to meet\n",
      "17_7.txt\n",
      "summary1:  A little slow , but all , but all , are\n",
      "summary2:  A convincing giallo with obligatory twists and red herrings , are\n",
      "18_7.txt\n",
      "summary1:  Her home in her to read at her spare time they become\n",
      "summary2:  A good film without nudity , or profanity , or write\n",
      "19_10.txt\n",
      "summary1:  Have to dislike jane fonda for her vietnam era actions , have\n",
      "summary2:  This film is that it is that it is that it and i look\n",
      "20_9.txt\n",
      "summary1:  All in all in all in all an excellent movie is\n",
      "summary2:  The triumph of the beauty of the main characters each rendered\n",
      "21_7.txt\n",
      "summary1:  But illiterate , and resourceful , the intelligent and the ending\n",
      "summary2:  But illiterate , stanley , and resourceful , and the ending\n",
      "22_8.txt\n",
      "summary1:  A real dunce though , and i wonder if he is\n",
      "summary2:  Are typical of the eighties , but at least they are\n",
      "23_7.txt\n",
      "summary1:  And marner , and a fairy tale , and he sings\n",
      "summary2:  The efforts of puss in boots when they by rights should\n",
      "24_8.txt\n",
      "summary1:  And the performances and the songs in this movie are worth seeing\n",
      "summary2:  And singer and he is a marvelous dancer and he is\n",
      "25_7.txt\n",
      "summary1:  The singing and the special fx are cheesy and the future held\n",
      "summary2:  And the singing and dancing is great , the special fx are\n",
      "26_7.txt\n",
      "summary1:  Is the suspect , but we know she is not the color is\n",
      "summary2:  The only thing that spoiled the color is being spilled and naked bodies are\n",
      "27_9.txt\n",
      "summary1:  With the threesome 's first shorts with the stooges as are\n",
      "summary2:  This excludes his much earlier vaudeville years with the stooges as frustrated\n",
      "28_9.txt\n",
      "summary1:  The corn , pop in the tape and get ready to go\n",
      "summary2:  The main character of the effect of the tape and is\n",
      "29_8.txt\n",
      "summary1:  For this and the dreadful red queen figurine , i felt\n",
      "summary2:  The move and the whole thing constantly on the film is\n",
      "30_10.txt\n",
      "summary1:  Coys ( 1957-1963 ) it is too bad that lydia reed has\n",
      "summary2:  The summer of the departed members of the cast and respected\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import os\n",
    "filenames = [f for f in os.listdir('.') if os.path.isfile(f)]\n",
    "for name in filenames: \n",
    "    a,b = name.split('.')\n",
    "    if b == 'txt':     \n",
    "        print(name)    \n",
    "        Z1 = read_text(name)\n",
    "        sigma_r = 2 \n",
    "        G1 = dict()\n",
    "        PRI1 = dict()\n",
    "        OpinosisGraph(Z1, G1, PRI1)\n",
    "        candidates = []\n",
    "        for keys in G1:\n",
    "            if(VSN(keys)):\n",
    "                clist = []\n",
    "                sum_sent = [keys]\n",
    "                score = 0\n",
    "                Traverse(clist,keys,score,PRI1[keys],sum_sent,1)\n",
    "                candidates = candidates + clist\n",
    "        C = eliminate_dup2(candidates)\n",
    "        if len(C) < 2:\n",
    "            sigma_r = 1\n",
    "            for keys in G1:\n",
    "                if(VSN(keys)):\n",
    "                    clist = []\n",
    "                    sum_sent = [keys]\n",
    "                    score = 0\n",
    "                    Traverse(clist,keys,score,PRI1[keys],sum_sent,1)\n",
    "                    candidates = candidates + clist\n",
    "        if len(C) < 2:\n",
    "            sigma_r = 0\n",
    "            for keys in G1:\n",
    "                if(VSN(keys)):\n",
    "                    clist = []\n",
    "                    sum_sent = [keys]\n",
    "                    score = 0\n",
    "                    Traverse(clist,keys,score,PRI1[keys],sum_sent,1)\n",
    "                    candidates = candidates + clist\n",
    "        summary = find_sum(C)\n",
    "        \n",
    "        print(\"summary1: \",summary[0])\n",
    "        print(\"summary2: \",summary[1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "modification:\n",
    "1.use the second generation, but the technical error in the first generation is kept\n",
    "Don't delete old PRI to ensure that Clists are not empty\n",
    "problem:\n",
    "1.Summaries are composed of some fragments of sentences(00_9.txt,01_7.txt)\n",
    "2.The repeatnedss within a sentence is still unsolved\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
